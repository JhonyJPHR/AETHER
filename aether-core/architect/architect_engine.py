# aether-core/architect/architect_engine.py
import os
import json
from openai import OpenAI
from colorama import Fore, Style

# Tenta carregar a API Key
try:
    from dotenv import load_dotenv
    load_dotenv()
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    AI_AVAILABLE = True
except:
    AI_AVAILABLE = False

class Architect:
    def __init__(self):
        print(f"{Fore.CYAN}[ARCHITECT] M√≥dulo de Diagn√≥stico Inteligente carregado.")

    def diagnose_and_fix(self, error_log, file_path):
        """
        L√™ o arquivo defeituoso e solicita uma corre√ß√£o √† IA.
        """
        print(f"{Fore.YELLOW}[ARCHITECT] üîç Analisando c√≥digo fonte em: {file_path}")
        
        # 1. Ler o c√≥digo "doente" (CORRE√á√ÉO APLICADA AQUI: encoding='utf-8')
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                source_code = f.read()
        except FileNotFoundError:
            print(f"{Fore.RED}[ERRO] Arquivo fonte n√£o encontrado!")
            return None
        except Exception as e:
            print(f"{Fore.RED}[ERRO LEITURA] N√£o foi poss√≠vel ler o arquivo: {e}")
            return None

        # 2. Montar o Prompt para a IA
        prompt = f"""
        Voc√™ √© o AETHER ARCHITECT, uma IA especialista em corrigir bugs cr√≠ticos em tempo real.
        
        CONTEXTO:
        O seguinte c√≥digo Python gerou um erro cr√≠tico em produ√ß√£o.
        
        ERRO DETECTADO:
        {error_log}
        
        C√ìDIGO FONTE ORIGINAL:
        ```python
        {source_code}
        ```
        
        SUA MISS√ÉO:
        1. Identifique a causa raiz l√≥gica do erro (ex: divis√£o por zero, null pointer).
        2. Reescreva o c√≥digo corrigindo o problema.
        3. Retorne APENAS o c√≥digo Python corrigido. Nada de explica√ß√µes.
        """

        print(f"{Fore.YELLOW}[ARCHITECT] üß† Consultando N√∫cleo de IA para solu√ß√£o...")

        # 3. Chamar a IA (Ou simular se n√£o tiver chave)
        if AI_AVAILABLE and os.getenv("OPENAI_API_KEY"):
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "Voc√™ √© uma IA de auto-corre√ß√£o de c√≥digo. Retorne apenas c√≥digo limpo."},
                        {"role": "user", "content": prompt}
                    ]
                )
                fixed_code = response.choices[0].message.content
                print(f"{Fore.GREEN}[ARCHITECT] üí° Solu√ß√£o gerada pela IA com sucesso!")
                
                # Limpeza b√°sica do markdown
                fixed_code = fixed_code.replace("```python", "").replace("```", "")
                return fixed_code
                
            except Exception as e:
                print(f"{Fore.RED}[ERRO AI] Falha na conex√£o: {e}")
                return self._simulation_mode(source_code)
        else:
            print(f"{Fore.MAGENTA}[ARCHITECT] ‚ö†Ô∏è Modo Simula√ß√£o Ativo (Sem API Key)")
            return self._simulation_mode(source_code)

    def _simulation_mode(self, source_code):
        """
        Modo de fallback para demonstra√ß√£o sem internet/API.
        """
        print(f"{Fore.MAGENTA}[SIMULATION] Aplicando patch pr√©-definido para 'ZeroDivisionError'...")
        
        if "amount / risk_factor" in source_code:
            fixed_code = source_code.replace(
                "result = amount / risk_factor", 
                "result = amount / (risk_factor if risk_factor != 0 else 1) # Aether Fix: Prevented Division by Zero"
            )
            return fixed_code
        return source_code